{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d51c09-7803-41eb-ab0c-dfe1bcd66564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell done executing\n"
     ]
    }
   ],
   "source": [
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "import json\n",
    "import lucene\n",
    "import os\n",
    "import ast\n",
    "from org.apache.lucene.store import MMapDirectory, SimpleFSDirectory, NIOFSDirectory\n",
    "from java.nio.file import Paths\n",
    "from org.apache.lucene.analysis.standard import StandardAnalyzer\n",
    "from org.apache.lucene.document import Document, Field, FieldType, TextField, StringField\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.index import FieldInfo, IndexWriter, IndexWriterConfig, IndexOptions, DirectoryReader\n",
    "from org.apache.lucene.search import IndexSearcher, BoostQuery, Query\n",
    "from org.apache.lucene.search.similarities import BM25Similarity\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "jsonKeys = ['created_utc', 'id', 'name', 'num_comments', 'over_18', 'permalink', 'score', 'selftext', 'spoiler', 'title', 'upvote_ratio', 'url', 'comments']\n",
    "pathlist = Path('jsonData/').glob('**/*.json')\n",
    "finalDocJson = 'group01_reddit_data.json'\n",
    "#finalDocJson = 'nfl_data_1_SAMPLE_SHORTENED.json'\n",
    "\n",
    "### run commented out code below ONCE to create the combined json file ###\n",
    "### comment out code below after json is created to make future cell runs faster ###\n",
    "# tempDoc = []\n",
    "# counter = 0\n",
    "# try:\n",
    "#     for path in pathlist:\n",
    "#         path_in_str = str(path)\n",
    "#         #print(path_in_str)\n",
    "#         with open(path_in_str, 'r') as data_file:\n",
    "#             counter += 1\n",
    "#             x = json.load(data_file)\n",
    "#             for i in range(len(x)):\n",
    "#                 if (x[i]['over_18'] == False and x[i]['spoiler'] == False):\n",
    "#                     x[i]['over_18'] = 'false'\n",
    "#                     x[i]['spoiler'] = 'false'\n",
    "#                 elif (x[i]['over_18'] == False and x[i]['spoiler'] == True):\n",
    "#                     x[i]['over_18'] = 'false'\n",
    "#                     x[i]['spoiler'] = 'true'\n",
    "#                 elif (x[i]['over_18'] == True and x[i]['spoiler'] == False):\n",
    "#                     x[i]['over_18'] = 'true'\n",
    "#                     x[i]['spoiler'] = 'false'\n",
    "#                 elif (x[i]['over_18'] == True and x[i]['spoiler'] == True):\n",
    "#                     x[i]['over_18'] = 'true'\n",
    "#                     x[i]['spoiler'] = 'true'\n",
    "#                 tempDoc.append(x[i])\n",
    "# except:\n",
    "#     print('error at json file:')\n",
    "#     print(counter)\n",
    "\n",
    "# with open(finalDocJson, 'w') as f:\n",
    "#     json.dump(tempDoc, f, indent=4)\n",
    "\n",
    "#######\n",
    "\n",
    "finalDoc = []\n",
    "with open(finalDocJson, 'r') as index_file:\n",
    "    finalDoc = json.load(index_file)\n",
    "\n",
    "def create_index(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "    store = SimpleFSDirectory(Paths.get(dir))\n",
    "    analyzer = StandardAnalyzer()\n",
    "    config = IndexWriterConfig(analyzer)\n",
    "    config.setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n",
    "    writer = IndexWriter(store, config)\n",
    "\n",
    "    ### discussion 6 slides #9 columns are: INDEXED-TOKENIZED-STORED ###\n",
    "    \n",
    "    # No-No-Yes = not on slides so idk\n",
    "    metaType = FieldType()\n",
    "    metaType.setStored(True)\n",
    "    metaType.setTokenized(False)\n",
    "\n",
    "    # No-No-No = Not relevant for searching\n",
    "    irrelevantType = FieldType()\n",
    "    irrelevantType.setStored(False)\n",
    "    irrelevantType.setTokenized(False)\n",
    "    \n",
    "    # Yes-No-Yes = reddit username\n",
    "    usernameType = FieldType()\n",
    "    usernameType.setStored(True)\n",
    "    usernameType.setTokenized(False)\n",
    "    usernameType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "\n",
    "    # Yes-No-No = Sensitive information\n",
    "    sensitiveType = FieldType()\n",
    "    sensitiveType.setStored(False)\n",
    "    sensitiveType.setTokenized(False)\n",
    "    sensitiveType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "\n",
    "    # Yes-Yes-Yes = Title, abstract\n",
    "    contextType = FieldType()\n",
    "    contextType.setStored(True)\n",
    "    contextType.setTokenized(True)\n",
    "    contextType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "\n",
    "    # Yes-Yes-No = Body\n",
    "    bodyType = FieldType()\n",
    "    bodyType.setStored(False)\n",
    "    bodyType.setTokenized(True)\n",
    "    bodyType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "    \n",
    "    for sample in finalDoc:\n",
    "        #dict_keys(['created_utc', 'id', 'name', 'num_comments', 'over_18', 'permalink', 'score', 'selftext', 'spoiler', 'title', 'upvote_ratio', 'url', 'comments'])\n",
    "        created_utc = sample[jsonKeys[0]]\n",
    "        id = sample[jsonKeys[1]]\n",
    "        name = sample[jsonKeys[2]]\n",
    "        num_comments = sample[jsonKeys[3]]\n",
    "        over_18 = sample[jsonKeys[4]]\n",
    "        permalink = sample[jsonKeys[5]]\n",
    "        score = sample[jsonKeys[6]]\n",
    "        selftext = sample[jsonKeys[7]]\n",
    "        spoiler = sample[jsonKeys[8]]\n",
    "        title = sample[jsonKeys[9]]\n",
    "        upvote_ratio = sample[jsonKeys[10]]\n",
    "        url = sample[jsonKeys[11]]\n",
    "        comments = sample[jsonKeys[12]]\n",
    "\n",
    "        # metaType, irrelevantType, usernameType, sensitiveType, contextType, bodyType\n",
    "        # all are temporarily set to contextType for now while testing #\n",
    "        doc = Document()\n",
    "        doc.add(Field(jsonKeys[0], str(created_utc), contextType))\n",
    "        doc.add(Field(jsonKeys[1], str(id), contextType))\n",
    "        doc.add(Field(jsonKeys[2], str(name), contextType))\n",
    "        doc.add(Field(jsonKeys[3], str(num_comments), contextType))\n",
    "        doc.add(Field(jsonKeys[4], str(over_18), contextType))\n",
    "        doc.add(Field(jsonKeys[5], str(permalink), contextType))\n",
    "        doc.add(Field(jsonKeys[6], str(score), contextType))\n",
    "        doc.add(Field(jsonKeys[7], str(selftext), contextType))\n",
    "        doc.add(Field(jsonKeys[8], str(spoiler), contextType))\n",
    "        doc.add(Field(jsonKeys[9], str(title), contextType))\n",
    "        doc.add(Field(jsonKeys[10], str(upvote_ratio), contextType))\n",
    "        doc.add(Field(jsonKeys[11], str(url), contextType))\n",
    "        doc.add(Field(jsonKeys[12], str(comments), contextType))\n",
    "        writer.addDocument(doc)\n",
    "    writer.close()\n",
    "\n",
    "#SHOULD FIX JSON OBJECTS IN COMMENTS(IP)\n",
    "def fix_comments_field(comments):\n",
    "    try:\n",
    "        if comments is None:\n",
    "            return []\n",
    "        if isinstance(comments, str):\n",
    "            # Check if comments are in valid JSON format\n",
    "            try:\n",
    "                comments = json.loads(comments)\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        elif isinstance(comments, list):\n",
    "            for i in range(len(comments)):\n",
    "                if isinstance(comments[i], dict) and 'replies' in comments[i]:\n",
    "                    replies = comments[i]['replies']\n",
    "                    if isinstance(replies, str):\n",
    "                        try:\n",
    "                            replies = json.loads(replies)\n",
    "                            comments[i]['replies'] = replies\n",
    "                        except json.JSONDecodeError:\n",
    "                            pass\n",
    "        return comments\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def retrieve(storedir, query):\n",
    "    searchDir = NIOFSDirectory(Paths.get(storedir))\n",
    "    searcher = IndexSearcher(DirectoryReader.open(searchDir))\n",
    "    \n",
    "    parser = QueryParser('title', StandardAnalyzer())\n",
    "    parsed_query = parser.parse(query)\n",
    "\n",
    "    print('Parsed Query: ')\n",
    "    print(parsed_query)\n",
    "\n",
    "    topDocs = searcher.search(parsed_query, 10).scoreDocs\n",
    "    #print('top docs: ')\n",
    "    #print(topDocs)\n",
    "    topkdocs = []\n",
    "    for hit in topDocs:\n",
    "        doc = searcher.doc(hit.doc)\n",
    "        comments = doc.get(\"comments\")\n",
    "        comments_list = ast.literal_eval(comments) if comments else []\n",
    "        first_comment = comments_list[0] if comments_list else {}\n",
    "        topkdocs.append({\n",
    "            \"documentScore\": hit.score,\n",
    "            \"title\": doc.get(\"title\"),\n",
    "            #\"body\": first_comment['body'] if first_comment else '',\n",
    "            #\"body\": doc.get(\"body\"), # this is wrong, maybe #print(sample_doc[0]['comments'][0]['body']) need to use this\n",
    "            \"body\": first_comment.get('body', ''),\n",
    "            \"post_time\": datetime.fromtimestamp(float(doc.get(\"created_utc\"))).strftime('%Y-%m-%d %H:%M:%S') # referenced https://stackoverflow.com/a/46914259\n",
    "        })\n",
    "\n",
    "    print('Top 10 Documents: ')\n",
    "    #print(topkdocs)\n",
    "    for i in range(len(topkdocs)):\n",
    "        position = i + 1\n",
    "        print(str(position) + ') ' + str(topkdocs[i]))\n",
    "\n",
    "\n",
    "lucene.initVM(vmargs=['-Djava.awt.headless=true']) # \"JVM is already running\n",
    "print('Cell done executing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7721d016-f2ac-412a-ac2f-1674295fb3cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Query: \n",
      "title:world title:cup title:2022\n",
      "Top 10 Documents: \n",
      "1) {'documentScore': 8.044605255126953, 'title': 'WORLD CUP 2022', 'body': ' Lmao Qatar to win is 0.0%', 'post_time': '2022-12-14 05:07:35'}\n",
      "2) {'documentScore': 7.412470817565918, 'title': 'Brazil World Cup 2022 list', 'body': 'Playing the old 5-5-5-5-6 formation', 'post_time': '2022-11-07 14:20:04'}\n",
      "3) {'documentScore': 7.132248401641846, 'title': 'Germanys squad for World Cup 2022', 'body': 'Did Germany as a nation collectively decide to stop producing strikers after Klose?', 'post_time': '2022-11-10 06:39:12'}\n",
      "4) {'documentScore': 7.132248401641846, 'title': 'World cup 2022 group stage complete', 'body': \"Iran and USA in one group, oh lord that's gonna be a fun watch\", 'post_time': '2022-06-14 15:55:52'}\n",
      "5) {'documentScore': 7.132248401641846, 'title': 'Argentina Squad for World Cup 2022', 'body': 'People are saying Garnacho is robbed but let’s be realistic. He only played like 4 good games. No disrespect but I don’t think he deserves such an opportunity like the World Cup.', 'post_time': '2022-11-11 07:44:25'}\n",
      "6) {'documentScore': 6.942017555236816, 'title': 'World map of all 2022 fifa world cup nations', 'body': 'What about Italy?...........Oh.', 'post_time': '2022-06-08 14:40:37'}\n",
      "7) {'documentScore': 6.405756950378418, 'title': '[Canada] have qualified for the 2022 FIFA World Cup', 'body': 'Watching Alphonso Davies tear up on his stream celebrating was so wholesome! Congrats to Canada!', 'post_time': '2022-03-27 14:54:21'}\n",
      "8) {'documentScore': 6.405756950378418, 'title': 'USA has been eliminated from the 2022 World Cup.', 'body': 'CONCACAF Faded', 'post_time': '2022-12-03 08:53:01'}\n",
      "9) {'documentScore': 6.401978492736816, 'title': 'Argentina have won their third World Cup title at the 2022 FIFA World Cup in Qatar!', 'body': 'The best final of all times?', 'post_time': '2022-12-18 09:54:53'}\n",
      "10) {'documentScore': 6.195402145385742, 'title': 'The most valuable squads heading to Qatar World Cup 2022', 'body': 'England not winning the WC just proves that English players are overpriced.', 'post_time': '2022-11-18 07:41:52'}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_index('lucene_partB_index/')\n",
    "docstest = retrieve('lucene_partB_index/', 'title:World Cup 2022') # this took like 50 seconds, could be faster if the data wasn't combined into a single json file i guess\n",
    "print(docstest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042b586-2e78-43b4-ae5a-daa5c3cab158",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script project-partB-code.ipynb\n",
    "with open('project-partB-code.py', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "with open('project-partB-code.py', 'w') as f:\n",
    "    for line in lines:\n",
    "        if 'nbconvert --to script' in line:\n",
    "            break\n",
    "        else:\n",
    "            f.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
