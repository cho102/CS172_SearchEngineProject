{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d51c09-7803-41eb-ab0c-dfe1bcd66564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell done executing\n"
     ]
    }
   ],
   "source": [
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "import json\n",
    "import lucene\n",
    "import os\n",
    "from org.apache.lucene.store import MMapDirectory, SimpleFSDirectory, NIOFSDirectory\n",
    "from java.nio.file import Paths\n",
    "from org.apache.lucene.analysis.standard import StandardAnalyzer\n",
    "from org.apache.lucene.document import Document, Field, FieldType, TextField, StringField\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.index import FieldInfo, IndexWriter, IndexWriterConfig, IndexOptions, DirectoryReader\n",
    "from org.apache.lucene.search import IndexSearcher, BoostQuery, Query\n",
    "from org.apache.lucene.search.similarities import BM25Similarity\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "jsonKeys = ['created_utc', 'id', 'name', 'num_comments', 'over_18', 'permalink', 'score', 'selftext', 'spoiler', 'title', 'upvote_ratio', 'url', 'comments']\n",
    "pathlist = Path('jsonData/').glob('**/*.json')\n",
    "finalDocJson = 'group01_reddit_data.json'\n",
    "\n",
    "### run commented out code below ONCE to create the combined json file ###\n",
    "### comment out code below after json is created to make future cell runs faster ###\n",
    "# tempDoc = []\n",
    "# counter = 0\n",
    "# try:\n",
    "#     for path in pathlist:\n",
    "#         path_in_str = str(path)\n",
    "#         #print(path_in_str)\n",
    "#         with open(path_in_str, 'r') as data_file:\n",
    "#             counter += 1\n",
    "#             x = json.load(data_file)\n",
    "#             for i in range(len(x)):\n",
    "#                 if (x[i]['over_18'] == False and x[i]['spoiler'] == False):\n",
    "#                     x[i]['over_18'] = 'false'\n",
    "#                     x[i]['spoiler'] = 'false'\n",
    "#                 elif (x[i]['over_18'] == False and x[i]['spoiler'] == True):\n",
    "#                     x[i]['over_18'] = 'false'\n",
    "#                     x[i]['spoiler'] = 'true'\n",
    "#                 elif (x[i]['over_18'] == True and x[i]['spoiler'] == False):\n",
    "#                     x[i]['over_18'] = 'true'\n",
    "#                     x[i]['spoiler'] = 'false'\n",
    "#                 elif (x[i]['over_18'] == True and x[i]['spoiler'] == True):\n",
    "#                     x[i]['over_18'] = 'true'\n",
    "#                     x[i]['spoiler'] = 'true'\n",
    "#                 tempDoc.append(x[i])\n",
    "# except:\n",
    "#     print('error at json file:')\n",
    "#     print(counter)\n",
    "\n",
    "# with open(finalDocJson, 'w') as f:\n",
    "#     json.dump(tempDoc, f, indent=4)\n",
    "\n",
    "#######\n",
    "\n",
    "finalDoc = []\n",
    "with open(finalDocJson, 'r') as index_file:\n",
    "    finalDoc = json.load(index_file)\n",
    "\n",
    "def create_index(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "    store = SimpleFSDirectory(Paths.get(dir))\n",
    "    analyzer = StandardAnalyzer()\n",
    "    config = IndexWriterConfig(analyzer)\n",
    "    config.setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n",
    "    writer = IndexWriter(store, config)\n",
    "\n",
    "    ### discussion 6 slides #9 columns are: INDEXED-TOKENIZED-STORED ###\n",
    "    \n",
    "    # No-No-Yes = not on slides so idk\n",
    "    metaType = FieldType()\n",
    "    metaType.setStored(True)\n",
    "    metaType.setTokenized(False)\n",
    "\n",
    "    # No-No-No = Not relevant for searching\n",
    "    irrelevantType = FieldType()\n",
    "    irrelevantType.setStored(False)\n",
    "    irrelevantType.setTokenized(False)\n",
    "    \n",
    "    # Yes-No-Yes = reddit username\n",
    "    usernameType = FieldType()\n",
    "    usernameType.setStored(True)\n",
    "    usernameType.setTokenized(False)\n",
    "    usernameType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "\n",
    "    # Yes-No-No = Sensitive information\n",
    "    sensitiveType = FieldType()\n",
    "    sensitiveType.setStored(False)\n",
    "    sensitiveType.setTokenized(False)\n",
    "    sensitiveType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "\n",
    "    # Yes-Yes-Yes = Title, abstract\n",
    "    contextType = FieldType()\n",
    "    contextType.setStored(True)\n",
    "    contextType.setTokenized(True)\n",
    "    contextType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "\n",
    "    # Yes-Yes-No = Body\n",
    "    bodyType = FieldType()\n",
    "    bodyType.setStored(False)\n",
    "    bodyType.setTokenized(True)\n",
    "    bodyType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "    \n",
    "    for sample in finalDoc:\n",
    "        #dict_keys(['created_utc', 'id', 'name', 'num_comments', 'over_18', 'permalink', 'score', 'selftext', 'spoiler', 'title', 'upvote_ratio', 'url', 'comments'])\n",
    "        created_utc = sample[jsonKeys[0]]\n",
    "        id = sample[jsonKeys[1]]\n",
    "        name = sample[jsonKeys[2]]\n",
    "        num_comments = sample[jsonKeys[3]]\n",
    "        over_18 = sample[jsonKeys[4]]\n",
    "        permalink = sample[jsonKeys[5]]\n",
    "        score = sample[jsonKeys[6]]\n",
    "        selftext = sample[jsonKeys[7]]\n",
    "        spoiler = sample[jsonKeys[8]]\n",
    "        title = sample[jsonKeys[9]]\n",
    "        upvote_ratio = sample[jsonKeys[10]]\n",
    "        url = sample[jsonKeys[11]]\n",
    "        comments = sample[jsonKeys[12]]\n",
    "\n",
    "        # metaType, irrelevantType, usernameType, sensitiveType, contextType, bodyType\n",
    "        # all are temporarily set to contextType for now while testing #\n",
    "        doc = Document()\n",
    "        doc.add(Field(jsonKeys[0], str(created_utc), contextType))\n",
    "        doc.add(Field(jsonKeys[1], str(id), contextType))\n",
    "        doc.add(Field(jsonKeys[2], str(name), contextType))\n",
    "        doc.add(Field(jsonKeys[3], str(num_comments), contextType))\n",
    "        doc.add(Field(jsonKeys[4], str(over_18), contextType))\n",
    "        doc.add(Field(jsonKeys[5], str(permalink), contextType))\n",
    "        doc.add(Field(jsonKeys[6], str(score), contextType))\n",
    "        doc.add(Field(jsonKeys[7], str(selftext), contextType))\n",
    "        doc.add(Field(jsonKeys[8], str(spoiler), contextType))\n",
    "        doc.add(Field(jsonKeys[9], str(title), contextType))\n",
    "        doc.add(Field(jsonKeys[10], str(upvote_ratio), contextType))\n",
    "        doc.add(Field(jsonKeys[11], str(url), contextType))\n",
    "        doc.add(Field(jsonKeys[12], str(comments), contextType))\n",
    "        writer.addDocument(doc)\n",
    "    writer.close()\n",
    "\n",
    "def retrieve(storedir, query):\n",
    "    searchDir = NIOFSDirectory(Paths.get(storedir))\n",
    "    searcher = IndexSearcher(DirectoryReader.open(searchDir))\n",
    "    \n",
    "    parser = QueryParser('title', StandardAnalyzer())\n",
    "    parsed_query = parser.parse(query)\n",
    "\n",
    "    print('Parsed Query: ')\n",
    "    print(parsed_query)\n",
    "\n",
    "    topDocs = searcher.search(parsed_query, 10).scoreDocs\n",
    "    #print('top docs: ')\n",
    "    #print(topDocs)\n",
    "    topkdocs = []\n",
    "    for hit in topDocs:\n",
    "        doc = searcher.doc(hit.doc)\n",
    "        topkdocs.append({\n",
    "            \"documentScore\": hit.score,\n",
    "            \"title\": doc.get(\"title\"),\n",
    "            \"body\": doc.get(\"body\"), # this is wrong, maybe #print(sample_doc[0]['comments'][0]['body']) need to use this\n",
    "            \"post_time\": datetime.fromtimestamp(float(doc.get(\"created_utc\"))).strftime('%Y-%m-%d %H:%M:%S') # referenced https://stackoverflow.com/a/46914259\n",
    "        })\n",
    "\n",
    "    print('Top 10 Documents: ')\n",
    "    #print(topkdocs)\n",
    "    for i in range(len(topkdocs)):\n",
    "        position = i + 1\n",
    "        print(str(position) + ') ' + str(topkdocs[i]))\n",
    "\n",
    "\n",
    "lucene.initVM(vmargs=['-Djava.awt.headless=true'])\n",
    "print('Cell done executing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7721d016-f2ac-412a-ac2f-1674295fb3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Query: \n",
      "title:world title:cup title:2022\n",
      "Top 10 Documents: \n",
      "1) {'documentScore': 8.044605255126953, 'title': 'WORLD CUP 2022'}\n",
      "2) {'documentScore': 7.412470817565918, 'title': 'Brazil World Cup 2022 list'}\n",
      "3) {'documentScore': 7.132248401641846, 'title': 'Germanys squad for World Cup 2022'}\n",
      "4) {'documentScore': 7.132248401641846, 'title': 'World cup 2022 group stage complete'}\n",
      "5) {'documentScore': 7.132248401641846, 'title': 'Argentina Squad for World Cup 2022'}\n",
      "6) {'documentScore': 6.942017555236816, 'title': 'World map of all 2022 fifa world cup nations'}\n",
      "7) {'documentScore': 6.405756950378418, 'title': '[Canada] have qualified for the 2022 FIFA World Cup'}\n",
      "8) {'documentScore': 6.405756950378418, 'title': 'USA has been eliminated from the 2022 World Cup.'}\n",
      "9) {'documentScore': 6.401978492736816, 'title': 'Argentina have won their third World Cup title at the 2022 FIFA World Cup in Qatar!'}\n",
      "10) {'documentScore': 6.195402145385742, 'title': 'The most valuable squads heading to Qatar World Cup 2022'}\n"
     ]
    }
   ],
   "source": [
    "create_index('lucene_partB_index/')\n",
    "retrieve('lucene_partB_index/', 'title:WORLD CUP 2022') # this took like 50 seconds, could be faster if the data wasn't combined into a single json file i guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03933810-141a-4124-82a8-5536061d8cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Query: \n",
      "body:oldest title:world\n",
      "Top 10 Documents: \n",
      "1) {'documentScore': 2.4090113639831543, 'title': 'Belgium World Cup Squad for World Cup', 'body': None, 'post_time': '2022-11-10 03:16:51'}\n",
      "2) {'documentScore': 2.3023815155029297, 'title': 'World map of all 2022 fifa world cup nations', 'body': None, 'post_time': '2022-06-08 14:40:37'}\n",
      "3) {'documentScore': 2.217965602874756, 'title': 'WORLD CUP 2022', 'body': None, 'post_time': '2022-12-14 05:07:35'}\n",
      "4) {'documentScore': 2.217965602874756, 'title': 'World Series hangover??', 'body': None, 'post_time': '2019-04-18 06:24:18'}\n",
      "5) {'documentScore': 2.15903377532959, 'title': 'How well would they fare in the World Cup, as WORLD XI??', 'body': None, 'post_time': '2022-04-04 00:16:47'}\n",
      "6) {'documentScore': 2.1272592544555664, 'title': 'FIBA WORLD CUP 2023', 'body': None, 'post_time': '2023-05-01 15:55:27'}\n",
      "7) {'documentScore': 2.0436806678771973, 'title': 'World Cup balls getting charged', 'body': None, 'post_time': '2022-11-29 20:58:07'}\n",
      "8) {'documentScore': 2.0436806678771973, 'title': 'Brazil World Cup 2022 list', 'body': None, 'post_time': '2022-11-07 14:20:04'}\n",
      "9) {'documentScore': 2.0436806678771973, 'title': 'Atlanta Braves World Series Champions', 'body': None, 'post_time': '2021-11-03 13:19:24'}\n",
      "10) {'documentScore': 1.993541955947876, 'title': 'Argentina have won their third World Cup title at the 2022 FIFA World Cup in Qatar!', 'body': None, 'post_time': '2022-12-18 09:54:53'}\n"
     ]
    }
   ],
   "source": [
    "#print(sample_doc[0]) # returns first dictionary entry in list\n",
    "#print(sample_doc[0]['comments']) # returns body and replies for comments of first dictionary entry\n",
    "#print(sample_doc[0]['comments'][0]) # returns first body and replies for first comment of first dictionary entry\n",
    "#print(sample_doc[0]['comments'][0]['body']) # returns body of first comment of first dictionary entry\n",
    "#print(sample_doc[0]['comments'][0]['replies']) # returns replies of first comment of first dictionary entry\n",
    "#print(sample_doc[0]['comments'][0]['replies'][0]) # returns first reply of first comment of first dictionary entry\n",
    "create_index('lucene_partB_index/')\n",
    "retrieve('lucene_partB_index/', 'body:oldest OR title:WORLD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90692513-58c4-401c-b3c8-8517344454b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-14 05:07:35\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "utc = '1671023255.0'\n",
    "print(datetime.fromtimestamp(float(utc)).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "#tzInfo = pytz.timezone('America/Los_Angeles')\n",
    "#dt = datetime.now(tz=tzInfo)\n",
    "#print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db14bac-b8a3-454e-a0f6-f2eb8948259c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
