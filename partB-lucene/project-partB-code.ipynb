{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d51c09-7803-41eb-ab0c-dfe1bcd66564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7f517bb04390>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "\n",
    "import json\n",
    "with open('jsonData/nfl_data_1.json', 'r') as user_file:\n",
    "    parsed_json = json.load(user_file)\n",
    "\n",
    "jsonKeys = list(parsed_json[0].keys())\n",
    "\n",
    "import lucene\n",
    "import os\n",
    "from org.apache.lucene.store import MMapDirectory, SimpleFSDirectory, NIOFSDirectory\n",
    "from java.nio.file import Paths\n",
    "from org.apache.lucene.analysis.standard import StandardAnalyzer\n",
    "from org.apache.lucene.document import Document, Field, FieldType, TextField, StringField\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.index import FieldInfo, IndexWriter, IndexWriterConfig, IndexOptions, DirectoryReader\n",
    "from org.apache.lucene.search import IndexSearcher, BoostQuery, Query\n",
    "from org.apache.lucene.search.similarities import BM25Similarity\n",
    "\n",
    "sample_doc = [\n",
    "    {\n",
    "        \"created_utc\": 1573415397.0,\n",
    "        \"id\": \"dugc2h\",\n",
    "        \"name\": \"t3_dugc2h\",\n",
    "        \"num_comments\": 2054,\n",
    "        \"over_18\": 'false', #need to modify value for all json key:value pairs so that its value is a string\n",
    "        \"permalink\": \"/r/nfl/comments/dugc2h/highlight_lamar_47yard_touchdown_run/\",\n",
    "        \"score\": 22559,\n",
    "        \"selftext\": \"\",\n",
    "        \"spoiler\": 'false', #need to modify value for all json key:value pairs so that its value is a string\n",
    "        \"title\": \"[Highlight] Lamar 47-yard touchdown run\",\n",
    "        \"upvote_ratio\": 0.97,\n",
    "        \"url\": \"https://streamable.com/5zv5f\",\n",
    "        \"comments\": [{\n",
    "            \"body\": \"No, you can\\u2019t just be out there doing that\",\n",
    "            \"replies\": [\"\\\"Wait a minute, that's illegal!\\\"\", \"1) You can't just be up there and just doin' a balk like that.\\n\\n1a. A balk is when you\\n\\n1b. Okay well listen. A balk is when you balk the\\n\\n1c. Let me start over\\n\\n1c-a. The pitcher is not allowed to do a motion to the, uh, batter, that prohibits the batter from doing, you know, just trying to hit the ball. You can't do that.\\n\\n1c-b. Once the pitcher is in the stretch, he can't be over here and say to the runner, like, \\\"I'm gonna get ya! I'm gonna tag you out! You better watch your butt!\\\" and then just be like he didn't even do that.\\n\\n1c-b(1). Like, if you're about to pitch and then don't pitch, you have to still pitch. You cannot not pitch. Does that make any sense?\\n\\n1c-b(2). You gotta be, throwing motion of the ball, and then, until you just throw it.\\n\\n1c-b(2)-a. Okay, well, you can have the ball up here, like this, but then there's the balk you gotta think about.\\n\\n1c-b(2)-b. Fairuza Balk hasn't been in any movies in forever. I hope she wasn't typecast as that racist lady in American History X.\\n\\n1c-b(2)-b(i). Oh wait, she was in The Waterboy too! That would be even worse.\\n\\n1c-b(2)-b(ii). \\\"get in mah bellah\\\" -- Adam Water, \\\"The Waterboy.\\\" Haha, classic...\\n\\n1c-b(3). Okay seriously though. A balk is when the pitcher makes a movement that, as determined by, when you do a move involving the baseball and field of\\n\\n2) Do not do a balk please.\", \"I'm pretty sure Lamar Jackson is playing a different game than most other QBs in the league.\", \"spin move, so smooth\", \"Hey you're not supposed to do that!\", \"This made me delete my pornhub account\", \"\\\"My lord... is that legal?\\\"\", \"That shit is unfair\"]\n",
    "        }]\n",
    "        },\n",
    "    {\n",
    "        \"created_utc\": 1553464446.0,\n",
    "        \"id\": \"b52429\",\n",
    "        \"name\": \"t3_b52429\",\n",
    "        \"num_comments\": 3666,\n",
    "        \"over_18\": 'false', #need to modify value for all json key:value pairs so that its value is a string\n",
    "        \"permalink\": \"/r/nfl/comments/b52429/gronk_to_retire/\",\n",
    "        \"score\": 22422,\n",
    "        \"selftext\": \"\",\n",
    "        \"spoiler\": 'false', #need to modify value for all json key:value pairs so that its value is a string\n",
    "        \"title\": \"Gronk to retire.\",\n",
    "        \"upvote_ratio\": 0.98,\n",
    "        \"url\": \"https://www.instagram.com/p/BvaCbK6BCvd/?utm_source=ig_share_sheet&igshid=1udchmdrqdsrl\",\n",
    "        \"comments\": [{\n",
    "            \"body\": \"Imagine telling Gronk when he was drafted that he would retire before the then-33-year-old Brady.\",\n",
    "            \"replies\": [\"Coaches & kickers. They're the only ones who outlast Brady.... Unless Brady gets the opposing coaches fired. \"]\n",
    "        }]\n",
    "    },\n",
    "    {\n",
    "        \"created_utc\": 1536526633.0,\n",
    "        \"id\": \"9egfjc\",\n",
    "        \"name\": \"t3_9egfjc\",\n",
    "        \"num_comments\": 1348,\n",
    "        \"over_18\": 'false', #need to modify value for all json key:value pairs so that its value is a string\n",
    "        \"permalink\": \"/r/nfl/comments/9egfjc/for_the_first_time_since_december_2016_the/\",\n",
    "        \"score\": 22418,\n",
    "        \"selftext\": \"\",\n",
    "        \"spoiler\": 'false', #need to modify value for all json key:value pairs so that its value is a string\n",
    "        \"title\": \"For the first time since December 2016 the Cleveland Browns have NOT lost the game! They TIE with the Steelers, 21-21\",\n",
    "        \"upvote_ratio\": 0.98,\n",
    "        \"url\": \"http://www.espn.com/nfl/game?gameId=401030718\",\n",
    "        \"comments\": [{\n",
    "            \"body\": \"Only the Browns could end a losing streak without actually winning.\",\n",
    "            \"replies\": [\"That losing streak has officially been upgraded to a winless streak, baby!\", \"This is the best take on this situation by far.\", \"This is the kind of event that builds a lore, the kind of trivia that will be brought up decades later whenever some other team goes on a losing streak.\\n\\n\\\"So and so are on a near record breaking losing streak. The other only team to have a losing streak this long was the 2016-2018 Cleveland Browns who broke their streak with a TIE of all things.\\\"\\n\\nWhat a fascinating game.\", \"I thought to myself \\\"This is the most Brownsian way of ending a losing streak.\\\"\", \"We truly live in the dankest timeline. \", \"They'll get their first win in ages against us next week.\", \"I\\u2019d rather a tie than a loss, feels bad man \", \"Baby steps\", \"Start all their players for Fantasy Football next week.\", \"Let's keep it up! 0-0-16\", \"This game was like a movie where the protagonist and the antagonist both die in the climatic fight\", \"Is it possible to learn this power?\", \">Only the Browns could end a losing streak without actually winning.\\n\\nOnly a **Browns** fan would consider this a victory. We still have a starting QB through week 1.\", \"Only the Steelers could tie with the Browns.\", \"It's a well known fact of life Hue can only win on Saturdays\", \"/thread\", \"Only the Browns could ruin the money I had on the game by screwing up their losing streak. \", \"look out they got the aints next week.\", \"How funny would it be if they tied every game this season?\", \"0-0-16 season incoming\", \"Be careful were coming next week!\", \"Actually laughed out loud LMAOO\", \"Lmao\", \"This is literally what everyone thought walking into this thread, hilarious. \", \"You beautiful son of a bitch. \", \"And the Saints may be the only team to end their winless streak\", \"We're going to tie the saints next\", \"*congratulations to the Armadillos on their non-loss*\", \"And yet the Cleveland Browns are off to their best start since 2004\", \"They lost with +5 turnover differential. \\n\\nOf teams with +5 turnover differential, 132 teams won, 4 lost, 1 tied. Cleveland accounts for 2 of the losses and the tie.\\n\\nThey managed to not lose in a statistically impressive manner.\"]\n",
    "        }]\n",
    "    }\n",
    "]\n",
    "\n",
    "def create_index(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "    store = SimpleFSDirectory(Paths.get(dir))\n",
    "    analyzer = StandardAnalyzer()\n",
    "    config = IndexWriterConfig(analyzer)\n",
    "    config.setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n",
    "    writer = IndexWriter(store, config)\n",
    "\n",
    "    ### discussion 6 slides #9 columns are: INDEXED-TOKENIZED-STORED ###\n",
    "    \n",
    "    # No-No-Yes = not on slides so idk\n",
    "    metaType = FieldType()\n",
    "    metaType.setStored(True)\n",
    "    metaType.setTokenized(False)\n",
    "\n",
    "    # No-No-No = Not relevant for searching\n",
    "    irrelevantType = FieldType()\n",
    "    irrelevantType.setStored(False)\n",
    "    irrelevantType.setTokenized(False)\n",
    "    \n",
    "    # Yes-No-Yes = reddit username\n",
    "    usernameType = FieldType()\n",
    "    usernameType.setStored(True)\n",
    "    usernameType.setTokenized(False)\n",
    "    usernameType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "\n",
    "    # Yes-No-No = Sensitive information\n",
    "    sensitiveType = FieldType()\n",
    "    sensitiveType.setStored(False)\n",
    "    sensitiveType.setTokenized(False)\n",
    "    sensitiveType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "\n",
    "    # Yes-Yes-Yes = Title, abstract\n",
    "    contextType = FieldType()\n",
    "    contextType.setStored(True)\n",
    "    contextType.setTokenized(True)\n",
    "    contextType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "\n",
    "    # Yes-Yes-No = Body\n",
    "    bodyType = FieldType()\n",
    "    bodyType.setStored(False)\n",
    "    bodyType.setTokenized(True)\n",
    "    bodyType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "    \n",
    "    for sample in sample_doc:\n",
    "        #dict_keys(['created_utc', 'id', 'name', 'num_comments', 'over_18', 'permalink', 'score', 'selftext', 'spoiler', 'title', 'upvote_ratio', 'url', 'comments'])\n",
    "        created_utc = sample[jsonKeys[0]]\n",
    "        id = sample[jsonKeys[1]]\n",
    "        name = sample[jsonKeys[2]]\n",
    "        num_comments = sample[jsonKeys[3]]\n",
    "        over_18 = sample[jsonKeys[4]]\n",
    "        permalink = sample[jsonKeys[5]]\n",
    "        score = sample[jsonKeys[6]]\n",
    "        selftext = sample[jsonKeys[7]]\n",
    "        spoiler = sample[jsonKeys[8]]\n",
    "        title = sample[jsonKeys[9]]\n",
    "        upvote_ratio = sample[jsonKeys[10]]\n",
    "        url = sample[jsonKeys[11]]\n",
    "        comments = sample[jsonKeys[12]]\n",
    "\n",
    "        # metaType, irrelevantType, usernameType, sensitiveType, contextType, bodyType\n",
    "        # all are temporarily set to contextType for now while testing #\n",
    "        doc = Document()\n",
    "        doc.add(Field(jsonKeys[0], str(created_utc), contextType))\n",
    "        doc.add(Field(jsonKeys[1], str(id), contextType))\n",
    "        doc.add(Field(jsonKeys[2], str(name), contextType))\n",
    "        doc.add(Field(jsonKeys[3], str(num_comments), contextType))\n",
    "        doc.add(Field(jsonKeys[4], str(over_18), contextType))\n",
    "        doc.add(Field(jsonKeys[5], str(permalink), contextType))\n",
    "        doc.add(Field(jsonKeys[6], str(score), contextType))\n",
    "        doc.add(Field(jsonKeys[7], str(selftext), contextType))\n",
    "        doc.add(Field(jsonKeys[8], str(spoiler), contextType))\n",
    "        doc.add(Field(jsonKeys[9], str(title), contextType))\n",
    "        doc.add(Field(jsonKeys[10], str(upvote_ratio), contextType))\n",
    "        doc.add(Field(jsonKeys[11], str(url), contextType))\n",
    "        doc.add(Field(jsonKeys[12], str(comments), contextType))\n",
    "        writer.addDocument(doc)\n",
    "    writer.close()\n",
    "\n",
    "def retrieve(storedir, query):\n",
    "    searchDir = NIOFSDirectory(Paths.get(storedir))\n",
    "    searcher = IndexSearcher(DirectoryReader.open(searchDir))\n",
    "    \n",
    "    parser = QueryParser('title', StandardAnalyzer())\n",
    "    parsed_query = parser.parse(query)\n",
    "\n",
    "    print('parsed_query: ')\n",
    "    print(parsed_query)\n",
    "\n",
    "    topDocs = searcher.search(parsed_query, 10).scoreDocs\n",
    "    print('top docs: ')\n",
    "    print(topDocs)\n",
    "    topkdocs = []\n",
    "    for hit in topDocs:\n",
    "        doc = searcher.doc(hit.doc)\n",
    "        topkdocs.append({\n",
    "            \"documentScore\": hit.score,\n",
    "            \"title\": doc.get(\"title\")\n",
    "        })\n",
    "\n",
    "    print('top 10 docs: ')\n",
    "    print(topkdocs)\n",
    "\n",
    "\n",
    "lucene.initVM(vmargs=['-Djava.awt.headless=true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7721d016-f2ac-412a-ac2f-1674295fb3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed_query: \n",
      "title:gronk\n",
      "top docs: \n",
      "JArray<object>[<ScoreDoc: doc=1 score=0.6282171 shardIndex=0>]\n",
      "top 10 docs: \n",
      "[{'documentScore': 0.6282171010971069, 'title': 'Gronk to retire.'}]\n"
     ]
    }
   ],
   "source": [
    "create_index('lucene_partB_index/')\n",
    "retrieve('lucene_partB_index/', 'title:Gronk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03933810-141a-4124-82a8-5536061d8cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#print(sample_doc[0]) # returns first dictionary entry in list\n",
    "#print(sample_doc[0]['comments']) # returns body and replies for comments of first dictionary entry\n",
    "#print(sample_doc[0]['comments'][0]) # returns first body and replies for first comment of first dictionary entry\n",
    "#print(sample_doc[0]['comments'][0]['body']) # returns body of first comment of first dictionary entry\n",
    "#print(sample_doc[0]['comments'][0]['replies']) # returns replies of first comment of first dictionary entry\n",
    "#print(sample_doc[0]['comments'][0]['replies'][0]) # returns first reply of first comment of first dictionary entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1abe7ee6-d7b1-4b7f-96b7-ebd1c954f0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jsonData/nfl_data_4.json\n",
      "jsonData/reddit_nba_newtop_data_4.json\n",
      "jsonData/sports5.json\n",
      "jsonData/sports3.json\n",
      "jsonData/nfl_data_7.json\n",
      "jsonData/sports9.json\n",
      "jsonData/nfl_data_5.json\n",
      "jsonData/reddit_soccer_data_1.json\n",
      "jsonData/nfl_data_6.json\n",
      "jsonData/reddit_nba_newtop_data_6.json\n",
      "jsonData/reddit_football_data_2.json\n",
      "jsonData/reddit_football_data_1.json\n",
      "jsonData/sports8.json\n",
      "jsonData/reddit_basketball_data_1.json\n",
      "jsonData/reddit_soccer_data_8.json\n",
      "jsonData/reddit_football_data_4.json\n",
      "jsonData/reddit_nba_newtop_data_2.json\n",
      "jsonData/reddit_soccer_data_15.json\n",
      "jsonData/reddit_nba_newtop_data_1.json\n",
      "jsonData/reddit_baseball_hot_data_2.json\n",
      "jsonData/sports2.json\n",
      "jsonData/sports11.json\n",
      "jsonData/reddit_nba_new_data_4.json\n",
      "jsonData/reddit_nba_newtop_data_5.json\n",
      "jsonData/reddit_mlb_top_data_3.json\n",
      "jsonData/reddit_baseball_top_data_4.json\n",
      "jsonData/sports10.json\n",
      "jsonData/reddit_nba_new_data_3.json\n",
      "jsonData/reddit_baseball_new_data_2.json\n",
      "jsonData/reddit_soccer_data_10.json\n",
      "jsonData/sports4.json\n",
      "jsonData/tennis_data_2.json\n",
      "jsonData/reddit_nba_new_data_2.json\n",
      "jsonData/nfl_data_3.json\n",
      "jsonData/sports7.json\n",
      "jsonData/reddit_soccer_data_4.json\n",
      "jsonData/tennis_data_3.json\n",
      "jsonData/reddit_nba_new_data_1.json\n",
      "jsonData/reddit_soccer_data_6.json\n",
      "jsonData/reddit_soccer_data_5.json\n",
      "jsonData/reddit_soccer_data_14.json\n",
      "jsonData/nfl_data_1.json\n",
      "jsonData/reddit_soccer_data_2.json\n",
      "jsonData/reddit_football_data_3.json\n",
      "jsonData/reddit_nba_newtop_data_3.json\n",
      "jsonData/reddit_baseball_top_data_2.json\n",
      "jsonData/reddit_soccer_data_13.json\n",
      "jsonData/reddit_mlb_top_data_1.json\n",
      "jsonData/nfl_data_2.json\n",
      "jsonData/reddit_soccer_data_12.json\n",
      "jsonData/sports12.json\n",
      "jsonData/reddit_baseball_top_data_1.json\n",
      "jsonData/reddit_soccer_data_7.json\n",
      "jsonData/reddit_baseball_hot_data_1.json\n",
      "jsonData/nfl_data_8.json\n",
      "jsonData/reddit_soccer_data_11.json\n",
      "jsonData/nfl_data_10.json\n",
      "jsonData/reddit_baseball_top_data_3.json\n",
      "jsonData/reddit_mlb_top_data_2.json\n",
      "jsonData/nfl_data_9.json\n",
      "jsonData/reddit_soccer_data_3.json\n",
      "jsonData/reddit_baseball_new_data_1.json\n",
      "jsonData/reddit_soccer_data_16.json\n",
      "jsonData/sports6.json\n",
      "jsonData/tennis_data_1.json\n",
      "jsonData/reddit_soccer_data_9.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "pathlist = Path('jsonData/').glob('**/*.json')\n",
    "tempIndex = []\n",
    "\n",
    "counter = 0\n",
    "try:\n",
    "    for path in pathlist:\n",
    "        path_in_str = str(path)\n",
    "        print(path_in_str)\n",
    "        with open(path_in_str, 'r') as data_file:\n",
    "            counter += 1\n",
    "            x = json.load(data_file)\n",
    "            for i in range(len(x)):\n",
    "                if (x[i]['over_18'] == False and x[i]['spoiler'] == False):\n",
    "                    x[i]['over_18'] = 'false'\n",
    "                    x[i]['spoiler'] = 'false'\n",
    "                elif (x[i]['over_18'] == False and x[i]['spoiler'] == True):\n",
    "                    x[i]['over_18'] = 'false'\n",
    "                    x[i]['spoiler'] = 'true'\n",
    "                elif (x[i]['over_18'] == True and x[i]['spoiler'] == False):\n",
    "                    x[i]['over_18'] = 'true'\n",
    "                    x[i]['spoiler'] = 'false'\n",
    "                elif (x[i]['over_18'] == True and x[i]['spoiler'] == True):\n",
    "                    x[i]['over_18'] = 'true'\n",
    "                    x[i]['spoiler'] = 'true'\n",
    "                tempIndex.append(x[i])\n",
    "except:\n",
    "    print(counter)\n",
    "\n",
    "output_formatted_json = 'group01_reddit_data.json'\n",
    "with open(output_formatted_json, 'w') as f:\n",
    "  json.dump(tempIndex, f, indent=4)\n",
    "\n",
    "# now can use group01_reddit_data.json with 'over_18' and 'spoiler' values set to strings\n",
    "#with open(output_formatted_json, 'r') as index_file:\n",
    "    #print(json.load(index_file)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef125a63-9822-4991-93fc-18367da7f473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "print(counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
